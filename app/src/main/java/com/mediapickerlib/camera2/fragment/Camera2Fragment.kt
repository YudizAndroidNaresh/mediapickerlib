/*
 * Copyright 2017 Lytcom
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *       http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.mediapickerlib.camera2.fragment

import android.Manifest
import android.animation.Animator
import android.animation.AnimatorListenerAdapter
import android.animation.AnimatorSet
import android.animation.ObjectAnimator
import android.annotation.SuppressLint
import android.app.Activity
import android.content.Context
import android.content.Intent
import android.content.pm.PackageManager
import android.content.res.Configuration
import android.graphics.*
import android.hardware.SensorManager
import android.hardware.camera2.*
import android.media.Image
import android.media.ImageReader
import android.media.MediaRecorder
import android.net.Uri
import android.os.*
import android.provider.MediaStore
import android.provider.Settings
import android.util.Log
import android.util.Size
import android.util.SparseIntArray
import android.view.*
import android.widget.Toast
import androidx.appcompat.app.AlertDialog
import androidx.core.app.ActivityCompat
import androidx.databinding.DataBindingUtil
import androidx.fragment.app.Fragment
import com.mediapickerlib.R
import com.mediapickerlib.activity.MediaPickerAct
import com.mediapickerlib.activity.PreviewAct
import com.mediapickerlib.adapter.MultiSelectionMediaAdapter
import com.mediapickerlib.adapter.SingleSelectionMediaAdapter
import com.mediapickerlib.base.MediaType
import com.mediapickerlib.base.SelectMedia
import com.mediapickerlib.base.addMediaToGallery
import com.mediapickerlib.builder.Media.Companion.getBuilder
import com.mediapickerlib.camera2.utils.*
import com.mediapickerlib.camera2.utils.CameraUtil.MEDIA_TYPE_IMAGE
import com.mediapickerlib.camera2.utils.CameraUtil.MEDIA_TYPE_VIDEO
import com.mediapickerlib.databinding.FragmentCamera2Binding
import com.mediapickerlib.fetcher.MediaFetcher
import com.mediapickerlib.modals.Img
import com.mediapickerlib.util.Constants
import com.mediapickerlib.util.Constants.EXTRA_MEDIA
import com.mediapickerlib.util.Constants.EXTRA_MEDIA_LIST
import com.mediapickerlib.util.Constants.VIDEO_TRIMMER_REQUEST_CODE
import com.mediapickerlib.util.Utility
import com.mediapickerlib.video_trimmer_java.VideoTrimmerActivity
import java.io.File
import java.io.FileOutputStream
import java.io.IOException
import java.text.DecimalFormat
import java.util.*
import java.util.concurrent.Semaphore
import java.util.concurrent.TimeUnit


class Camera2Fragment : Fragment(), View.OnClickListener {

    private lateinit var mBinding: FragmentCamera2Binding

    private lateinit var mAdapter: SingleSelectionMediaAdapter
    private val REQUEST_OPEN_PREVIEW_SCREEN = 100

    private var mLastImageDate: Long = 0
    private var mLastVideoDate: Long = 0
    private var mLastMediaDate: Long = 0

    /**
     * lastClickedTime contains last clicked time of view to prevent double click
     */
    protected var lastClickedTime: Long? = 0L
    private val MAX_CLICK_INTERVAL = 1500L

    private var mCropRegion: Rect? = null

    private var mAFRegions = AutoFocusHelper.getZeroWeightRegion()

    private var mAERegions = AutoFocusHelper.getZeroWeightRegion()

    private var mAspectRatio = CameraConstants.DEFAULT_ASPECT_RATIO

    private val mPreviewSizes = SizeMap()

    /**
     * ID of the current [CameraDevice].
     */
    private var mCameraId: String? = null

    /**
     * Recording Timer
     */
    private var mCountDownTimer: CountDownTimer? = null

    /**
     * A [CameraCaptureSession] for camera preview.
     */
    private var mPreviewSession: CameraCaptureSession? = null

    /**
     * A reference to the opened [CameraDevice].
     */
    private var mCameraDevice: CameraDevice? = null


    /**
     * [CaptureRequest.Builder] for the camera preview
     */
    private var mPreviewRequestBuilder: CaptureRequest.Builder? = null

    /**
     * [CaptureRequest] generated by [.mPreviewRequestBuilder]
     */
    private var mPreviewRequest: CaptureRequest? = null


    private var mCameraCharacteristics: CameraCharacteristics? = null

    /**
     * The current state of camera state for taking pictures.
     *
     * @see .mCaptureCallback
     */
    private var mState = STATE_PREVIEW

    /**
     * A [Semaphore] to prevent the app from exiting before closing the camera.
     */
    private val mCameraOpenCloseLock = Semaphore(1)

    /**
     * The current camera auto focus mode
     */
    // Revert
    var autoFocus = true
        set(autoFocus) {
            if (this.autoFocus == autoFocus) {
                return
            }
            field = autoFocus
            if (mPreviewRequestBuilder != null) {
                updateAutoFocus()
                if (mPreviewSession != null) {
                    try {
                        mPreviewSession!!.setRepeatingRequest(
                            mPreviewRequestBuilder!!.build(),
                            mCaptureCallback, mBackgroundHandler
                        )
                    } catch (e: CameraAccessException) {
                        field = !this.autoFocus
                    }

                }
            }
        }

    /**
     * Whether the current camera device supports auto focus or not.
     */
    /**
     * The auto focus is supported or not.
     */
    var isAutoFocusSupported = true
        private set

    /**
     * The current camera flash mode
     */
    // Revert
    var flash = CameraConstants.FLASH_AUTO
        set(flash) {
            if (this.flash == flash) {
                return
            }
            val saved = this.flash
            field = flash
            if (mPreviewRequestBuilder != null) {
                updateFlash(mPreviewRequestBuilder)
                if (mPreviewSession != null) {
                    try {
                        mPreviewSession!!.setRepeatingRequest(
                            mPreviewRequestBuilder!!.build(),
                            mCaptureCallback, mBackgroundHandler
                        )
                    } catch (e: CameraAccessException) {
                        field = saved
                    }

                }
            }
        }

    /**
     * Whether the current camera device supports flash or not.
     */
    /**
     * The flash is supported or not.
     */
    var isFlashSupported = true
        private set

    /**
     * The current camera facing mode
     */
    var facing = CameraConstants.FACING_BACK
        set(facing) {
            if (this.facing == facing) {
                return
            }
            field = facing
            if (isCameraOpened) {
                stop()
                start()
            }
        }

    /**
     * Whether the current camera device can switch back/front or not.
     */
    /**
     * The facing is supported or not.
     */
    var isFacingSupported = true
        private set

    /**
     * Orientation of the camera sensor
     */
    private var mSensorOrientation: Int = 0

    /**
     * The [Size] of camera preview.
     */
    private var mPreviewSize: Size? = null

    /**
     * The [Size] of video recording.
     */
    private var mVideoSize: Size? = null

    /**
     * MediaRecorder
     */
    private var mMediaRecorder: MediaRecorder? = null

    /**
     * Whether the camera is recording video now
     */
    var isRecordingVideo: Boolean = false
        private set

    /**
     * Whether the camera is manual focusing now
     */
    private var mIsManualFocusing: Boolean = false

    /**
     * An additional thread for running tasks that shouldn't block the UI.
     */
    private var mBackgroundThread: HandlerThread? = null

    /**
     * A [Handler] for running tasks in the background.
     */
    private var mBackgroundHandler: Handler? = null

    /**
     * An [ImageReader] that handles still image capture.
     */
    private var mImageReader: ImageReader? = null

    /**
     * The output file path of video recording.
     */
    private var mNextVideoAbsolutePath: String? = null

    /**
     * The output file path of take picture.
     */
    private var mNextPictureAbsolutePath: String? = null

    /**
     * Get Orientation of the device
     */
    private var mOrientationListener: OrientationEventListener? = null

    /**
     * Rotation degree of camera
     */
    private var mCamRotation = 0

    /**
     * Using for zoom finger
     */
    var mFingerSpacing = 0f
    var mZoomLevel = 1f
    var mMaximumZoomLevel: Float = 0.toFloat()
    var mZoomRect: Rect? = null

    /**
     * Zoom while move finger
     */
    private var mXtouchMove = 0f
    private var mYtouchMove = 0f

    /**
     * Set Geasture
     */
    private var mGestureDetector: GestureDetector? = null

    /**
     * [TextureView.SurfaceTextureListener] handles several lifecycle events on a
     * [TextureView].
     */
    private val mSurfaceTextureListener = object : TextureView.SurfaceTextureListener {

        override fun onSurfaceTextureAvailable(texture: SurfaceTexture, width: Int, height: Int) {
            //Log.e(TAG, "onSurfaceTextureAvailable:w  "+width+" h "+height);
            openCamera(width, height)
        }

        override fun onSurfaceTextureSizeChanged(texture: SurfaceTexture, width: Int, height: Int) {
            configureTransform(width, height)
        }

        override fun onSurfaceTextureDestroyed(texture: SurfaceTexture): Boolean {
            if (mBinding.texture != null) {
                mBinding.texture.surfaceTextureListener = null
            }
            return true
        }

        override fun onSurfaceTextureUpdated(texture: SurfaceTexture) {}

    }


    /**
     * [CameraDevice.StateCallback] is called when [CameraDevice] changes its state.
     */
    private val mStateCallback = object : CameraDevice.StateCallback() {

        override fun onOpened(cameraDevice: CameraDevice) {
            // This method is called when the camera is opened.  We start camera preview here.
            mCameraOpenCloseLock.release()
            mCameraDevice = cameraDevice
            createCameraPreviewSession()
        }

        override fun onDisconnected(cameraDevice: CameraDevice) {
            mCameraOpenCloseLock.release()
            cameraDevice.close()
            mCameraDevice = null
        }

        override fun onError(cameraDevice: CameraDevice, error: Int) {
            mCameraOpenCloseLock.release()
            cameraDevice.close()
            mCameraDevice = null
            val activity = activity
            if (null != activity) {
                showToast("Camera is error: $error")
                activity.finish()
            }
        }

    }


    /**
     * This a callback object for the [ImageReader]. "onImageAvailable" will be called when a
     * still image is ready to be saved.
     */
    private val mOnImageAvailableListener = ImageReader.OnImageAvailableListener { reader ->
        mNextPictureAbsolutePath = pictureFilePath
        mBackgroundHandler!!.post(
            ImageSaver(
                reader.acquireNextImage(),
                File(mNextPictureAbsolutePath),
                mBinding.texture.bitmap
            )
        )
        //showToast("Picture saved: " + mNextPictureAbsolutePath);
        Log.i(TAG, "Picture saved: " + mNextPictureAbsolutePath)
    }


    /**
     * A [CameraCaptureSession.CaptureCallback] that handles events related to JPEG capture.
     */
    private val mCaptureCallback = object : CameraCaptureSession.CaptureCallback() {

        private fun process(result: CaptureResult) {
            //  Log.i(TAG, "CaptureCallback mState: " + mState);
            when (mState) {
                STATE_PREVIEW -> {
                }// We have nothing to do when the camera preview is working normally.
                STATE_WAITING_LOCK -> {
                    val afState = result.get(CaptureResult.CONTROL_AF_STATE)
                    Log.i(TAG, "STATE_WAITING_LOCK afState: " + afState)
                    if (afState == null) {
                        mState = STATE_PICTURE_TAKEN
                        captureStillPicture()
                    } else if (CaptureResult.CONTROL_AF_STATE_FOCUSED_LOCKED == afState || CaptureResult.CONTROL_AF_STATE_NOT_FOCUSED_LOCKED == afState) {
                        // CONTROL_AE_STATE can be null on some devices
                        val aeState = result.get(CaptureResult.CONTROL_AE_STATE)
                        if (aeState == null || aeState == CaptureResult.CONTROL_AE_STATE_CONVERGED) {
                            mState = STATE_PICTURE_TAKEN
                            captureStillPicture()
                        } else {
                            runPrecaptureSequence()
                        }
                    }
                }
                STATE_WAITING_PRECAPTURE -> {
                    // CONTROL_AE_STATE can be null on some devices
                    val aeState = result.get(CaptureResult.CONTROL_AE_STATE)
                    if (aeState == null ||
                        aeState == CaptureResult.CONTROL_AE_STATE_PRECAPTURE ||
                        aeState == CaptureRequest.CONTROL_AE_STATE_FLASH_REQUIRED
                    ) {
                        mState = STATE_WAITING_NON_PRECAPTURE
                    }
                }
                STATE_WAITING_NON_PRECAPTURE -> {
                    // CONTROL_AE_STATE can be null on some devices
                    val aeState = result.get(CaptureResult.CONTROL_AE_STATE)
                    if (aeState == null || aeState != CaptureResult.CONTROL_AE_STATE_PRECAPTURE) {
                        mState = STATE_PICTURE_TAKEN
                        captureStillPicture()
                    }
                }
            }
        }

        override fun onCaptureProgressed(
            session: CameraCaptureSession,
            request: CaptureRequest,
            partialResult: CaptureResult
        ) {
            process(partialResult)
        }

        override fun onCaptureCompleted(
            session: CameraCaptureSession,
            request: CaptureRequest,
            result: TotalCaptureResult
        ) {
            process(result)
        }

    }

    private val recordHoldListener = View.OnLongClickListener {
        // Do something when your hold starts here.
        if (!isRecordingVideo)
            startRecordingVideo()
        true
    }


    private val recordTouchListener = View.OnTouchListener { pView, pEvent ->
        pView.onTouchEvent(pEvent)
        // We're only interested in when the button is released.
        if (pEvent.action == MotionEvent.ACTION_DOWN) {
            mBinding.imgPreview.isEnabled = false
            mBinding.imgSwitchCamera.isEnabled = false
        }
        if (pEvent.action == MotionEvent.ACTION_UP) {
            mBinding.imgPreview.isEnabled = true
            mBinding.imgSwitchCamera.isEnabled = true

            if (isRecordingVideo)
                stopRecordingVideo()
        } else if (pEvent.action == MotionEvent.ACTION_MOVE) {
            if (mXtouchMove == 0f) {
                mXtouchMove = pEvent.getX(0)
                mYtouchMove = pEvent.getY(0)
            }
            if (isRecordingVideo)
                handleZoom(pEvent)
        }
        false
    }

    internal val cameraCharacteristics: CameraCharacteristics?
        get() {
            val manager = activity!!.getSystemService(Context.CAMERA_SERVICE) as CameraManager
            try {
                return manager.getCameraCharacteristics(mCameraId)
            } catch (e: CameraAccessException) {
                e.printStackTrace()
            }

            return null
        }

    private val textureTouchListener = View.OnTouchListener { pView, event ->
        if (mGestureDetector != null) {
            mGestureDetector!!.onTouchEvent(event)
        }
        handleZoom(event)
    }

    val supportedAspectRatios: Set<AspectRatio>
        get() = mPreviewSizes.ratios()

    val isCameraOpened: Boolean
        get() = mCameraDevice != null

    private val mAutoFocusRunnable = Runnable {
        if (mPreviewRequestBuilder != null) {
            mIsManualFocusing = false
            updateAutoFocus()
            if (mPreviewSession != null) {
                try {
                    mPreviewSession!!.setRepeatingRequest(
                        mPreviewRequestBuilder!!.build(),
                        mCaptureCallback, mBackgroundHandler
                    )
                } catch (e: CameraAccessException) {
                    Log.e(TAG, "Failed to set manual focus.", e)
                }

            }
        }
    }

    private/*final File dir = context.getExternalFilesDir(null);
        return (dir == null ? "" : (dir.getAbsolutePath() + "/"))
            + System.currentTimeMillis() + ".mp4";*/ val videoFilePath: String
        get() = CameraUtil.getOutputMediaFile(MEDIA_TYPE_VIDEO).absolutePath

    private/*final File dir = context.getExternalFilesDir(null);
        return (dir == null ? "" : (dir.getAbsolutePath() + "/"))
            + System.currentTimeMillis() + ".jpg";*/ val pictureFilePath: String
        get() = CameraUtil.getOutputMediaFile(MEDIA_TYPE_IMAGE).absolutePath


    /**
     * Logic to Prevent the Launch Twice if User makes
     * the Tap(Click) very Fast.
     */
    private val isMultiClick: Boolean
        get() {
            if (SystemClock.elapsedRealtime() - lastClickedTime!! < MAX_CLICK_INTERVAL) {
                return true
            }
            lastClickedTime = SystemClock.elapsedRealtime()

            return false
        }

    /**
     * Shows a [Toast] on the UI thread.
     *
     * @param text The message to show
     */
    private fun showToast(text: String) {
        val activity = activity
        activity?.runOnUiThread { Toast.makeText(activity, text, Toast.LENGTH_SHORT).show() }
    }

    /**
     * We choose a largest picture size with mAspectRatio
     */
    internal fun choosePictureSize(choices: Array<Size>): Size {
        val pictureSizes = Arrays.asList(*choices)
        Collections.sort(pictureSizes, CompareSizesByArea())
        val maxIndex = pictureSizes.size - 1
        for (i in maxIndex downTo 0) {
            if (pictureSizes[i].width == pictureSizes[i].height * mAspectRatio.x / mAspectRatio.y) {
                return pictureSizes[i]
            }
        }
        return pictureSizes[maxIndex]
    }

    /**
     * We choose a largest video size with mAspectRatio. Also, we don't use sizes
     * larger than 1080p, since MediaRecorder cannot handle such a high-resolution video.
     *
     * @param choices The list of available sizes
     * @return The video size
     */
    internal fun chooseVideoSize(choices: Array<Size>): Size {
        val videoSizes = Arrays.asList(*choices)
        val supportedVideoSizes = ArrayList<Size>()
        Collections.sort(videoSizes, CompareSizesByArea())
        for (i in videoSizes.indices.reversed()) {
            if (videoSizes[i].width <= MAX_PREVIEW_WIDTH && videoSizes[i].height <= MAX_PREVIEW_HEIGHT) {
                supportedVideoSizes.add(videoSizes[i])
                if (videoSizes[i].width == videoSizes[i].height * mAspectRatio.x / mAspectRatio.y) {
                    return videoSizes[i]
                }
            }
        }
        return if (supportedVideoSizes.size > 0) supportedVideoSizes[0] else choices[choices.size - 1]
    }

    /**
     * Given `choices` of `Size`s supported by a camera, choose the smallest one that
     * is at least as large as the respective texture view size, and that is at most as large as the
     * respective max size, and whose aspect ratio matches with the specified value. If such size
     * doesn't exist, choose the largest one that is at most as large as the respective max size,
     * and whose aspect ratio matches with the specified value.
     *
     * @param choices           The list of sizes that the camera supports for the intended output
     * class
     * @param textureViewWidth  The width of the texture view relative to sensor coordinate
     * @param textureViewHeight The height of the texture view relative to sensor coordinate
     * @param maxWidth          The maximum width that can be chosen
     * @param maxHeight         The maximum height that can be chosen
     * @return The optimal `Size`, or an arbitrary one if none were big enough
     */
    internal fun chooseOptimalSize(
        choices: Array<Size>, textureViewWidth: Int,
        textureViewHeight: Int, maxWidth: Int, maxHeight: Int
    ): Size {
        mPreviewSizes.clear()
        // Collect the supported resolutions that are at least as big as the preview Surface
        val bigEnough = ArrayList<Size>()
        // Collect the supported resolutions that are smaller than the preview Surface
        val notBigEnough = ArrayList<Size>()
        val w = mAspectRatio.x
        val h = mAspectRatio.y
        for (option in choices) {
            if (option.width <= maxWidth && option.height <= maxHeight) {
                mPreviewSizes.add(
                    com.mediapickerlib.camera2.utils.Size(
                        option.width,
                        option.height
                    )
                )
                if (option.height == option.width * h / w) {
                    if (option.width >= textureViewWidth && option.height >= textureViewHeight) {
                        bigEnough.add(option)
                    } else {
                        notBigEnough.add(option)
                    }
                }
            }
        }

        // Pick the smallest of those big enough. If there is no one big enough, pick the
        // largest of those not big enough.
        if (bigEnough.size > 0) {
            return Collections.min(bigEnough, CompareSizesByArea())
        } else if (notBigEnough.size > 0) {
            return Collections.max(notBigEnough, CompareSizesByArea())
        } else {
            Log.e(TAG, "Couldn't find any suitable preview size")
            mAspectRatio = AspectRatio.of(4, 3)
            val sortedSet = mPreviewSizes.sizes(mAspectRatio)
            if (sortedSet != null) {
                val lastSize = sortedSet.last()
                return Size(lastSize.width, lastSize.height)
            }
            mAspectRatio = AspectRatio.of(choices[0].width, choices[0].height)
            return choices[0]
        }
    }

    override fun onCreateView(
        inflater: LayoutInflater, container: ViewGroup?,
        savedInstanceState: Bundle?
    ): View? {
        mBinding = DataBindingUtil.inflate(inflater, R.layout.fragment_camera2, container, false)
        return mBinding.root
    }

    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {
        if (!hasPermissionsGranted(VIDEO_PERMISSIONS)) {
            requestCameraPermission()
        }
        mBinding.click = this

        initView(view)

        setAdapter()
        setRecentImage()
        checkOrientation()
    }
    /**
     * Get Recent image and Set
     */
    private fun setRecentImage() {
        if (!hasPermissionsGranted(VIDEO_PERMISSIONS)) {
            return
        }
        val bitmap =
            if (mNextPictureAbsolutePath != null) Uri.fromFile(File(mNextPictureAbsolutePath)) else CameraUtil.getLatestPic(
                activity
            )
        ImageLoader.loadCircleImage(mBinding.imgPreview, bitmap)
    }

    private fun initView(view: View) {

        mBinding.relCapture.isEnabled = false
        mBinding.imgPreview.isEnabled = false
        mBinding.imgSwitchCamera.isEnabled = false

        when (getBuilder().mediaType) {
            MediaType.IMAGE -> {
                mBinding.texture.setOnTouchListener(textureTouchListener)
            }
            MediaType.VIDEO -> {
                mBinding.relCapture.setOnTouchListener(recordTouchListener)
                mBinding.relCapture.setOnLongClickListener(recordHoldListener)
            }
            MediaType.BOTH -> {
                mBinding.texture.setOnTouchListener(textureTouchListener)
                mBinding.relCapture.setOnTouchListener(recordTouchListener)
                mBinding.relCapture.setOnLongClickListener(recordHoldListener)
            }
        }

        /**
         * For Adjust Focus on Tab
         */
        mGestureDetector =
            GestureDetector(context, object : GestureDetector.SimpleOnGestureListener() {
                override fun onSingleTapUp(e: MotionEvent): Boolean {
                    setFocusViewWidthAnimation(e.x.toInt().toFloat(), e.y.toInt().toFloat())
                    setManualFocusAt(e.x.toInt(), e.y.toInt())
                    return true
                }
            })
    }

    /**
     * setAdapter for display capture image or record video list and user also select or deselect capture media
     */

    private fun setAdapter() {
        //TODO Change adp
        /*mAdapter = MultiSelectionMediaAdapter(
             context!!,
             object : SingleSelectionMediaAdapter.OnSelectedMediaAdapterListener {
                 override fun onMediaSelected(position: Int) {
                    // uiUpdate()
                 }
             })*/
        //mAdapter = MediaAdapter(context!!, this)
        mAdapter= SingleSelectionMediaAdapter(context!!, ArrayList(),object :SingleSelectionMediaAdapter.OnSelectedMediaAdapterListener{
            override fun onMediaSelected(position: Int) {

                //select media form recyclerview
                openPreviewScreen( mAdapter.getImg(position))
            }
        })
        mBinding.rvMedia.adapter = mAdapter
        updateMedia()
    }


    fun openPreviewScreen(media: Img) {
        if (media.isVideo){
            val intent = Intent(
                activity!!,
                VideoTrimmerActivity::class.java
            )
            intent.putExtra(EXTRA_MEDIA, media.url)
            activity!!.startActivityForResult(intent,VIDEO_TRIMMER_REQUEST_CODE)
            return
        }else{
            val intent = Intent(context, PreviewAct::class.java)
            intent.putExtra(EXTRA_MEDIA_LIST, arrayListOf(media))
            startActivityForResult(intent, REQUEST_OPEN_PREVIEW_SCREEN)
        }
    }

    private fun updateMedia() {
        val lastImageDateCur = Utility.getCursorOfLastImageDate(context)
        lastImageDateCur?.let {
            if (it.count == 0) return@let
            it.moveToNext()
            mLastImageDate =
                it.getLong(it.getColumnIndex(MediaStore.Images.Media.DATE_TAKEN))
        }

        val lastVideoDateCur = Utility.getCursorOfLastVideoDate(context)
        lastVideoDateCur?.let {
            if (it.count == 0) return@let
            it.moveToNext()
            mLastVideoDate =
                it.getLong(it.getColumnIndex(MediaStore.Video.Media.DATE_TAKEN))
        }

        /**
         * if not found image or video then display no media found UI
         */
        if (mLastImageDate == 0L && mLastVideoDate == 0L) {
            // setUI()
            return
        }

        mLastMediaDate =
            if (mLastImageDate <= mLastVideoDate) mLastImageDate else mLastVideoDate

        //mAdapter.clearList()

        val INSTANTLIST = ArrayList<Img>()

        INSTANTLIST.addAll(getData(Calendar.getInstance().time, Utility.getRecentDate()))
        INSTANTLIST.addAll(getData(Utility.getRecentDate(), Utility.getLastWeekDate()))
        INSTANTLIST.addAll(getData(Utility.getLastWeekDate(), Utility.getLastMonthDate()))

        object : MediaFetcher(context, mLastMediaDate) {
            override fun onPostExecute(imgs: ArrayList<Img>?) {
                super.onPostExecute(imgs)
                imgs?.let {
                    mAdapter.addMedias(it)
                    //setUI()
                }
            }
        }.execute()
        mAdapter.addMedias(INSTANTLIST)

        // setUI()
    }



    private fun getData(startDate: Date, endDate: Date): ArrayList<Img> {
        val TEMPLIST = ArrayList<Img>()
        /**
         * START get recent image
         */
        val cursorImage = Utility.getImageCursorByDate(context, startDate, endDate)
        val calendar = Calendar.getInstance()

        cursorImage?.let {
            val dateImage = it.getColumnIndex(MediaStore.Images.Media.DATE_TAKEN)
            val dataImage = it.getColumnIndex(MediaStore.Images.Media.DATA)
            val contentUrlImage = it.getColumnIndex(MediaStore.Images.Media._ID)
            val sizeImage = it.getColumnIndex(MediaStore.Images.Media.SIZE)
            for (i in 0 until it.count) {
                it.moveToNext()
                val path = Uri.withAppendedPath(
                    MediaStore.Images.Media.EXTERNAL_CONTENT_URI,
                    "" + it.getInt(contentUrlImage)
                )
                calendar.timeInMillis = it.getLong(dateImage)
                val dateDifference = Utility.getDateDifference(context, calendar)
                TEMPLIST.add(
                    Img(
                        "" + dateDifference, "" + path, it.getString(dataImage),
                        it.getLong(sizeImage), false, "", calendar.time
                    )
                )
            }
            it.close()
        }

        val cursorVideo = Utility.getVideoCursorByDate(context, startDate, endDate)
        cursorVideo?.let {
            val dateVideo = it.getColumnIndex(MediaStore.Video.Media.DATE_TAKEN)
            val dataVideo = it.getColumnIndex(MediaStore.Video.Media.DATA)
            val contentUrlVideo = it.getColumnIndex(MediaStore.Video.Media._ID)
            val sizeVideo = it.getColumnIndex(MediaStore.Video.Media.SIZE)

            for (i in 0 until it.count) {
                it.moveToNext()
                val path = Uri.withAppendedPath(
                    MediaStore.Video.Media.EXTERNAL_CONTENT_URI,
                    "" + it.getInt(contentUrlVideo)
                )
                calendar.timeInMillis = it.getLong(dateVideo)
                val dateDifference = Utility.getDateDifference(context, calendar)

                TEMPLIST.add(
                    Img(
                        "" + dateDifference,
                        "" + path,
                        it.getString(dataVideo),
                        it.getLong(sizeVideo),
                        true,
                        "",
                        calendar.time
                    )
                )
            }
            it.close()
        }

        TEMPLIST.sort()

        /**
         * add header
         */
        if (TEMPLIST.size > 0) {
            calendar.timeInMillis = TEMPLIST[0].dateTaken.time + 1
            /* TEMPLIST.add(
                 0, Img(
                     "" + Utility.getDateDifference(context, calendar), "", "",
                     0, false, "", calendar.time
                 )
             )*/
        }
        /**
         * END get recent media
         */
        return TEMPLIST
    }


    fun openPreviewScreen(mediaList: ArrayList<Img>) {
        val intent = Intent(context, PreviewAct::class.java)
        intent.putExtra(EXTRA_MEDIA_LIST, mediaList)
        startActivityForResult(intent, REQUEST_OPEN_PREVIEW_SCREEN)
    }

    /**
     * This for getting correct orientation of Device and
     * rotate the image
     */
    private fun checkOrientation() {
        mOrientationListener = object : OrientationEventListener(
            activity,
            SensorManager.SENSOR_DELAY_NORMAL
        ) {
            override fun onOrientationChanged(orientation: Int) {
                var orientation = orientation

                val info = 90

                if (orientation == OrientationEventListener.ORIENTATION_UNKNOWN) return

                orientation = (orientation + 45) / 90 * 90

                if (facing == CameraCharacteristics.LENS_FACING_BACK) {
                    mCamRotation = (info + orientation) % 360
                } else {
                    mCamRotation = (info - orientation + 360) % 360
                }
            }
        }

        if (mOrientationListener!!.canDetectOrientation() == true) {
            Log.v(TAG, "Can detect orientation")
            mOrientationListener!!.enable()
        } else {
            Log.v(TAG, "Cannot detect orientation")
            mOrientationListener!!.disable()
        }
    }

    override fun onResume() {
        super.onResume()
        start()
    }

    override fun onPause() {
        stop()
        super.onPause()
    }

    fun start() {
        startBackgroundThread()

        // When the screen is turned off and turned back on, the SurfaceTexture is already
        // available, and "onSurfaceTextureAvailable" will not be called. In that case, we can open
        // a camera and start preview from here (otherwise, we wait until the surface is ready in
        // the SurfaceTextureListener).
        if (mBinding.texture.isAvailable) {
            openCamera(mBinding.texture.width, mBinding.texture.height)
        } else {
            mBinding.texture.surfaceTextureListener = mSurfaceTextureListener
        }
    }

    fun stop() {
        closeCamera()
        stopBackgroundThread()
    }

    /**
     * Focus view animation
     */
    private fun setFocusViewWidthAnimation(x: Float, y: Float) {
        mBinding.focusView.visibility = View.VISIBLE

        mBinding.focusView.x = x - mBinding.focusView.width / 2
        mBinding.focusView.y = y - mBinding.focusView.height / 2

        val scaleX = ObjectAnimator.ofFloat(mBinding.focusView, "scaleX", 1f, 0.6f)
        val scaleY = ObjectAnimator.ofFloat(mBinding.focusView, "scaleY", 1f, 0.6f)
        val alpha =
            ObjectAnimator.ofFloat(mBinding.focusView, "alpha", 1f, 0.3f, 1f, 0.3f, 1f, 0.3f, 1f)
        val animSet = AnimatorSet()
        animSet.addListener(object : AnimatorListenerAdapter() {
            override fun onAnimationEnd(animation: Animator) {
                mBinding.focusView.visibility = View.INVISIBLE
            }
        })
        animSet.play(scaleX).with(scaleY).before(alpha)
        animSet.duration = 300
        animSet.start()
    }

    private fun hasPermissionsGranted(permissions: Array<String>): Boolean {
        for (permission in permissions) {
            if (ActivityCompat.checkSelfPermission(
                    activity!!,
                    permission
                ) != PackageManager.PERMISSION_GRANTED
            ) {
                return false
            }
        }
        return true
    }


    private fun handleZoom(event: MotionEvent): Boolean {
        try {
            if (!hasPermissionsGranted(VIDEO_PERMISSIONS))
                return true

            val rect =
                cameraCharacteristics!!.get(CameraCharacteristics.SENSOR_INFO_ACTIVE_ARRAY_SIZE)
                    ?: return false
            val currentFingerSpacing: Float
            if (event.pointerCount == 2) { //Multi touch.
                currentFingerSpacing = CameraUtil.getFingerSpacing(event)
                var delta = 0.05f
                if (mFingerSpacing != 0f) {
                    if (currentFingerSpacing > mFingerSpacing) {
                        if (mMaximumZoomLevel - mZoomLevel <= delta) {
                            delta = mMaximumZoomLevel - mZoomLevel
                        }
                        mZoomLevel = mZoomLevel + delta
                    } else if (currentFingerSpacing < mFingerSpacing) {
                        if (mZoomLevel - delta < 1f) {
                            delta = mZoomLevel - 1f
                        }
                        mZoomLevel = mZoomLevel - delta
                    }
                    applyZoom(mZoomLevel, rect)
                }
                mFingerSpacing = currentFingerSpacing
            } else if (event.pointerCount == 1 && isRecordingVideo) { //Single touch point, needs to return true in order to detect one more touch point
                currentFingerSpacing = CameraUtil.getFingerSpacing(event, mXtouchMove, mYtouchMove)
                var delta = 0.05f
                if (mYtouchMove > event.getY(0) && currentFingerSpacing >= 100) {
                    if (mFingerSpacing != 0f) {
                        if (currentFingerSpacing > mFingerSpacing) {
                            if (mMaximumZoomLevel - mZoomLevel <= delta) {
                                delta = mMaximumZoomLevel - mZoomLevel
                            }
                            mZoomLevel = mZoomLevel + delta
                        } else if (currentFingerSpacing < mFingerSpacing) {
                            if (mZoomLevel - delta < 1f) {
                                delta = mZoomLevel - 1f
                            }
                            mZoomLevel = mZoomLevel - delta
                        }

                        applyZoom(mZoomLevel, rect)
                    }
                    mFingerSpacing = currentFingerSpacing
                } else {
                    if (mZoomLevel - delta < 1f) {
                        delta = mZoomLevel - 1f
                    }
                    mZoomLevel = mZoomLevel - delta
                    applyZoom(mZoomLevel, rect)
                }
                //return true;
            } else
                return true

            mPreviewSession!!.setRepeatingRequest(
                mPreviewRequestBuilder!!.build(),
                mCaptureCallback,
                mBackgroundHandler
            )

            return true
        } catch (e: Exception) {
            e.printStackTrace()
            // if (BuildConfig.DEBUG) e.printStackTrace();
            /*if (mCaptureCallback != null) {
                    post(new Runnable() {
                        @Override
                        public void run() {
                            cameraErrorCallback.onCameraError(e);
                        }
                    });
                }*/
            return false
        }

    }

    private fun applyZoom(zoomLevel: Float, rect: Rect) {
        Log.e(TAG, "mZoomLevel: $zoomLevel")
        val ratio = 1.toFloat() / zoomLevel
        val croppedWidth = rect.width() - Math.round(rect.width().toFloat() * ratio)
        val croppedHeight = rect.height() - Math.round(rect.height().toFloat() * ratio)
        mZoomRect = Rect(
            croppedWidth / 2, croppedHeight / 2,
            rect.width() - croppedWidth / 2, rect.height() - croppedHeight / 2
        )

        mPreviewRequestBuilder!!.set(CaptureRequest.SCALER_CROP_REGION, mZoomRect)
    }

    /**
     * Gets whether you should show UI with rationale for requesting permissions.
     *
     * @param permissions The permissions your app wants to request.
     * @return Whether you can show permission rationale UI.
     */
    private fun shouldShowRequestPermissionRationale(permissions: Array<String>): Boolean {
        for (permission in permissions) {
            if (ActivityCompat.shouldShowRequestPermissionRationale(activity!!, permission)) {
                return true
            }
        }
        return false
    }

    private fun requestCameraPermission() {
        /* if (shouldShowRequestPermissionRationale(VIDEO_PERMISSIONS)) {
            //new ConfirmationDialog().show(getChildFragmentManager(), FRAGMENT_DIALOG);
            showToast("Please allow camera permissions");
        } else {
            requestPermissions(VIDEO_PERMISSIONS, REQUEST_CAMERA_PERMISSION);
        }*/
        requestPermissions(VIDEO_PERMISSIONS, REQUEST_CAMERA_PERMISSION)
    }

    override fun onRequestPermissionsResult(
        requestCode: Int, permissions: Array<String>,
        grantResults: IntArray
    ) {
        Log.e(TAG, "onRequestPermissionsResult " + grantResults.size)
        super.onRequestPermissionsResult(requestCode, permissions, grantResults)
        if (requestCode == REQUEST_CAMERA_PERMISSION) {
            if (grantResults.size > 0
                && grantResults[0] == PackageManager.PERMISSION_GRANTED && grantResults[1] == PackageManager.PERMISSION_GRANTED && grantResults[2] == PackageManager.PERMISSION_GRANTED
            ) {
                setRecentImage()
            } else if (shouldShowRequestPermissionRationale(Manifest.permission.CAMERA) || shouldShowRequestPermissionRationale(
                    Manifest.permission.WRITE_EXTERNAL_STORAGE
                )
                || shouldShowRequestPermissionRationale(Manifest.permission.RECORD_AUDIO)
            ) {
                activity!!.finish()
            } else if (grantResults[0] != PackageManager.PERMISSION_GRANTED && grantResults[1] != PackageManager.PERMISSION_GRANTED && grantResults[2] != PackageManager.PERMISSION_GRANTED) {
                showSnackbarForSetting("" + getString(R.string.permission_pending_camera_storage_microphone))
            } else if (grantResults[0] != PackageManager.PERMISSION_GRANTED) {
                showSnackbarForSetting("" + getString(R.string.permission_pending_camera))
            } else if (grantResults[1] != PackageManager.PERMISSION_GRANTED) {
                showSnackbarForSetting("" + getString(R.string.permission_pending_storage))
            } else if (grantResults[2] != PackageManager.PERMISSION_GRANTED) {
                showSnackbarForSetting("" + getString(R.string.permission_pending_microphone))
            }
        }
    }

    internal fun showSnackbarForSetting(messgae: String) {
        AlertDialog.Builder(context!!)
            .setMessage(messgae)
            .setPositiveButton(R.string.settings) { dialog, which ->
                try {
                    val intent = Intent(Settings.ACTION_APPLICATION_DETAILS_SETTINGS)
                    intent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK)
                    intent.data = Uri.fromParts("package", activity!!.packageName, null)
                    startActivity(intent)
                } catch (e: Exception) {
                    e.printStackTrace()
                }

                dialog.dismiss()
            }
            .setNegativeButton(android.R.string.cancel) { dialog, which -> dialog.dismiss() }
            .setIcon(android.R.drawable.ic_dialog_alert)
            .show()
    }

    /**
     * Setup member variables related to camera.
     *
     * @param width  The width of available size for camera preview
     * @param height The height of available size for camera preview
     */
    private fun setupCameraOutputs(width: Int, height: Int) {
        val activity = activity
        val internalFacing = INTERNAL_FACINGS.get(facing)
        val manager = activity!!.getSystemService(Context.CAMERA_SERVICE) as CameraManager
        try {
            val cameraIds = manager.cameraIdList
            isFacingSupported = cameraIds.size > 1
            for (cameraId in cameraIds) {
                mCameraCharacteristics = manager.getCameraCharacteristics(cameraId)

                val facing = mCameraCharacteristics!!.get(CameraCharacteristics.LENS_FACING)
                if (facing == null || facing != internalFacing) {
                    continue
                }

                val map = mCameraCharacteristics!!.get(
                    CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP
                ) ?: continue

                mMaximumZoomLevel =
                    mCameraCharacteristics!!.get(CameraCharacteristics.SCALER_AVAILABLE_MAX_DIGITAL_ZOOM)

                // Find out if we need to swap dimension to get the preview size relative to sensor
                // coordinate.
                val displayRotation = activity.windowManager.defaultDisplay.rotation

                mSensorOrientation =
                    mCameraCharacteristics!!.get(CameraCharacteristics.SENSOR_ORIENTATION)
                var swappedDimensions = false
                when (displayRotation) {
                    Surface.ROTATION_0, Surface.ROTATION_180 -> if (mSensorOrientation == 90 || mSensorOrientation == 270) {
                        swappedDimensions = true
                    }
                    Surface.ROTATION_90, Surface.ROTATION_270 -> if (mSensorOrientation == 0 || mSensorOrientation == 180) {
                        swappedDimensions = true
                    }
                    else -> Log.e(TAG, "Display rotation is invalid: $displayRotation")
                }

                val displaySize = Point()
                activity.windowManager.defaultDisplay.getRealSize(displaySize)
                var rotatedPreviewWidth = width
                var rotatedPreviewHeight = height
                var maxPreviewWidth = displaySize.x
                var maxPreviewHeight = displaySize.y

                if (swappedDimensions) {
                    rotatedPreviewWidth = height
                    rotatedPreviewHeight = width
                    maxPreviewWidth = displaySize.y
                    maxPreviewHeight = displaySize.x
                }

                if (maxPreviewWidth > MAX_PREVIEW_WIDTH) {
                    maxPreviewWidth = MAX_PREVIEW_WIDTH
                }

                if (maxPreviewHeight > MAX_PREVIEW_HEIGHT) {
                    maxPreviewHeight = MAX_PREVIEW_HEIGHT
                }

                // Danger, W.R.! Attempting to use too large a preview size could exceed the camera
                // bus' bandwidth limitation, resulting in gorgeous previews but the storage of
                // garbage capture data.
                mPreviewSize = chooseOptimalSize(
                    map.getOutputSizes(SurfaceTexture::class.java),
                    rotatedPreviewWidth, rotatedPreviewHeight, maxPreviewWidth,
                    maxPreviewHeight
                )

                mVideoSize = chooseVideoSize(map.getOutputSizes(MediaRecorder::class.java))

                // For still image captures, we use the largest available size.
                val largest = choosePictureSize(map.getOutputSizes(ImageFormat.JPEG))

                mImageReader = ImageReader.newInstance(
                    largest.width, largest.height,
                    ImageFormat.JPEG, /*maxImages*/2
                )
                mImageReader!!.setOnImageAvailableListener(
                    mOnImageAvailableListener, mBackgroundHandler
                )

                // We fit the aspect ratio of TextureView to the size of preview we picked.
                val orientation = resources.configuration.orientation
                if (orientation == Configuration.ORIENTATION_LANDSCAPE) {
                    mBinding.texture.setAspectRatio(
                        mPreviewSize!!.width, mPreviewSize!!.height
                    )
                } else {
                    mBinding.texture.setAspectRatio(
                        mPreviewSize!!.height, mPreviewSize!!.width
                    )
                }

                checkAutoFocusSupported()
                checkFlashSupported()

                mCropRegion = AutoFocusHelper.cropRegionForZoom(
                    mCameraCharacteristics,
                    CameraConstants.ZOOM_REGION_DEFAULT.toFloat()
                )

                mCameraId = cameraId
                Log.i(TAG, "CameraId: $mCameraId ,isFlashSupported: $isFlashSupported")
                return
            }
        } catch (e: CameraAccessException) {
            e.printStackTrace()
        } catch (e: NullPointerException) {
            showToast(getString(R.string.camera_error))
            // Currently an NPE is thrown when the Camera2API is used but not supported on the
        }

    }

    /**
     * Check if the auto focus is supported.
     */
    private fun checkAutoFocusSupported() {
        val modes = mCameraCharacteristics!!.get(CameraCharacteristics.CONTROL_AF_AVAILABLE_MODES)
        isAutoFocusSupported = !(modes == null || modes.size == 0 ||
                modes.size == 1 && modes[0] == CameraCharacteristics.CONTROL_AF_MODE_OFF)
    }

    /**
     * Check if the flash is supported.
     */
    private fun checkFlashSupported() {
        val available = mCameraCharacteristics!!.get(CameraCharacteristics.FLASH_INFO_AVAILABLE)
        isFlashSupported = available ?: false
    }

    /**
     * Opens the camera specified by [Camera2Fragment.mCameraId].
     */
    @SuppressLint("MissingPermission")
    private fun openCamera(width: Int, height: Int) {
        if (!hasPermissionsGranted(VIDEO_PERMISSIONS)) {
            //requestCameraPermission();
            return
        }
        mBinding.relCapture.isEnabled = true
        mBinding.imgPreview.isEnabled = true
        mBinding.imgSwitchCamera.isEnabled = true

        setupCameraOutputs(width, height)
        configureTransform(width, height)
        val activity = activity

        //((CameraActivity)getActivity()).setAspectRatioTextureView(width, height);

        val manager = activity!!.getSystemService(Context.CAMERA_SERVICE) as CameraManager
        try {
            if (!mCameraOpenCloseLock.tryAcquire(
                    CameraConstants.OPEN_CAMERA_TIMEOUT_MS,
                    TimeUnit.MILLISECONDS
                )
            ) {
                throw RuntimeException("Time out waiting to lock camera opening.")
            }
            mMediaRecorder = MediaRecorder()
            manager.openCamera(mCameraId, mStateCallback, mBackgroundHandler)
            /**
             *
             */
            checkAspectRatio(supportedAspectRatios)

        } catch (e: CameraAccessException) {
            e.printStackTrace()
        } catch (e: InterruptedException) {
            throw RuntimeException("Interrupted while trying to lock camera opening.", e)
        }

    }

    fun checkAspectRatio(ratios: Set<AspectRatio>) {
        val aspectRatios = ratios.toTypedArray()
    }

    /**
     * Closes the current [CameraDevice].
     */
    private fun closeCamera() {
        try {
            mCameraOpenCloseLock.acquire()
            if (null != mPreviewSession) {
                mPreviewSession!!.close()
                mPreviewSession = null
            }
            if (null != mCameraDevice) {
                mCameraDevice!!.close()
                mCameraDevice = null
            }
            if (null != mMediaRecorder) {
                mMediaRecorder!!.release()
                mMediaRecorder = null
            }
            if (null != mImageReader) {
                mImageReader!!.close()
                mImageReader = null
            }
            mBinding.linTimer.visibility = View.GONE
            mBinding.imgCameraVideo.visibility = View.GONE
            mBinding.txtTime.text = "00:00"
            if (mCountDownTimer != null) mCountDownTimer!!.cancel()
        } catch (e: InterruptedException) {
            throw RuntimeException("Interrupted while trying to lock camera closing.", e)
        } finally {
            mCameraOpenCloseLock.release()
        }
    }

    /**
     * Starts a background thread and its [Handler].
     */
    private fun startBackgroundThread() {
        mBackgroundThread = HandlerThread("CameraBackground")
        mBackgroundThread!!.start()
        mBackgroundHandler = object : Handler(mBackgroundThread!!.looper) {
            override fun handleMessage(msg: Message) {
                super.handleMessage(msg)
                when (msg.what) {
                    MSG_CAPTURE_PICTURE_WHEN_FOCUS_TIMEOUT -> {
                        mState = STATE_PICTURE_TAKEN
                        captureStillPicture()
                    }
                    else -> {
                    }
                }

            }
        }
    }

    /**
     * Stops the background thread and its [Handler].
     */
    private fun stopBackgroundThread() {
        mBackgroundThread!!.quitSafely()
        try {
            mBackgroundThread!!.join()
            mBackgroundThread = null
            mBackgroundHandler = null
        } catch (e: InterruptedException) {
            e.printStackTrace()
        }

    }

    /**
     * Creates a new [CameraCaptureSession] for camera preview.
     */
    private fun createCameraPreviewSession() {
        try {
            val texture = mBinding.texture.surfaceTexture

            // We configure the size of default buffer to be the size of camera preview we want.
            texture.setDefaultBufferSize(mPreviewSize!!.width, mPreviewSize!!.height)

            // This is the output Surface we need to start preview.
            val surface = Surface(texture)

            // We set up a CaptureRequest.Builder with the output Surface.
            mPreviewRequestBuilder =
                mCameraDevice!!.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW)
            mPreviewRequestBuilder!!.addTarget(surface)

            // Here, we create a CameraCaptureSession for camera preview.
            mCameraDevice!!.createCaptureSession(
                Arrays.asList(surface, mImageReader!!.surface),
                object : CameraCaptureSession.StateCallback() {

                    override fun onConfigured(cameraCaptureSession: CameraCaptureSession) {
                        // The camera is already closed
                        if (null == mCameraDevice) {
                            return
                        }

                        // When the session is ready, we start displaying the preview.
                        mPreviewSession = cameraCaptureSession
                        try {
                            // Auto focus should be continuous for camera preview.
                            //                            mPreviewRequestBuilder.set(CaptureRequest.CONTROL_AF_MODE,
                            //                                CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_PICTURE);
                            updateAutoFocus()
                            // Flash is automatically enabled when necessary.
                            updateFlash(mPreviewRequestBuilder)

                            // Finally, we start displaying the camera preview.
                            mPreviewRequest = mPreviewRequestBuilder!!.build()
                            mPreviewSession!!.setRepeatingRequest(
                                mPreviewRequest!!,
                                mCaptureCallback, mBackgroundHandler
                            )
                        } catch (e: Exception) {
                            e.printStackTrace()
                        }

                    }

                    override fun onConfigureFailed(
                        cameraCaptureSession: CameraCaptureSession
                    ) {
                        showToast("Create preview configure failed")
                    }
                }, mBackgroundHandler
            )
        } catch (e: CameraAccessException) {
            e.printStackTrace()
        }

    }

    /**
     * Configures the necessary [Matrix] transformation to `mBinding.texture`.
     * This method should be called after the camera preview size is determined in
     * setupCameraOutputs and also the size of `mBinding.texture` is fixed.
     *
     * @param viewWidth  The width of `mBinding.texture`
     * @param viewHeight The height of `mBinding.texture`
     */
    private fun configureTransform(viewWidth: Int, viewHeight: Int) {
        val activity = activity
        if (null == mBinding.texture || null == mPreviewSize || null == activity) {
            return
        }
        val rotation = activity.windowManager.defaultDisplay.rotation
        val matrix = Matrix()
        val viewRect = RectF(0f, 0f, viewWidth.toFloat(), viewHeight.toFloat())
        val bufferRect =
            RectF(0f, 0f, mPreviewSize!!.height.toFloat(), mPreviewSize!!.width.toFloat())
        val centerX = viewRect.centerX()
        val centerY = viewRect.centerY()
        if (Surface.ROTATION_90 == rotation || Surface.ROTATION_270 == rotation) {
            bufferRect.offset(centerX - bufferRect.centerX(), centerY - bufferRect.centerY())
            matrix.setRectToRect(viewRect, bufferRect, Matrix.ScaleToFit.FILL)
            val scale = Math.max(
                viewHeight.toFloat() / mPreviewSize!!.height,
                viewWidth.toFloat() / mPreviewSize!!.width
            )
            matrix.postScale(scale, scale, centerX, centerY)
            matrix.postRotate((90 * (rotation - 2)).toFloat(), centerX, centerY)
        } else if (Surface.ROTATION_180 == rotation) {
            matrix.postRotate(180f, centerX, centerY)
        }
        mBinding.texture!!.setTransform(matrix)
    }

    fun getAspectRatio(): AspectRatio {
        return mAspectRatio
    }

    fun setAspectRatio(aspectRatio: AspectRatio?): Boolean {
        if (aspectRatio == null || aspectRatio == mAspectRatio ||
            !mPreviewSizes.ratios().contains(aspectRatio)
        ) {
            return false
        }
        mAspectRatio = aspectRatio
        if (isCameraOpened) {
            stop()
            start()
        }
        return true
    }

    /**
     * Updates the internal state of flash to [.mFlash].
     */
    internal fun updateFlash(requestBuilder: CaptureRequest.Builder?) {
        if (!isFlashSupported) {
            return
        }
        when (flash) {
            CameraConstants.FLASH_OFF -> {
                requestBuilder!!.set(
                    CaptureRequest.CONTROL_AE_MODE,
                    CaptureRequest.CONTROL_AE_MODE_ON
                )
                requestBuilder.set(
                    CaptureRequest.FLASH_MODE,
                    CaptureRequest.FLASH_MODE_OFF
                )
            }
            CameraConstants.FLASH_ON -> {
                requestBuilder!!.set(
                    CaptureRequest.CONTROL_AE_MODE,
                    CaptureRequest.CONTROL_AE_MODE_ON_ALWAYS_FLASH
                )
                requestBuilder.set(
                    CaptureRequest.FLASH_MODE,
                    CaptureRequest.FLASH_MODE_OFF
                )
            }
            CameraConstants.FLASH_TORCH -> {
                requestBuilder!!.set(
                    CaptureRequest.CONTROL_AE_MODE,
                    CaptureRequest.CONTROL_AE_MODE_ON
                )
                requestBuilder.set(
                    CaptureRequest.FLASH_MODE,
                    CaptureRequest.FLASH_MODE_TORCH
                )
            }
            CameraConstants.FLASH_AUTO -> {
                requestBuilder!!.set(
                    CaptureRequest.CONTROL_AE_MODE,
                    CaptureRequest.CONTROL_AE_MODE_ON_AUTO_FLASH
                )
                requestBuilder.set(
                    CaptureRequest.FLASH_MODE,
                    CaptureRequest.FLASH_MODE_OFF
                )
            }
            CameraConstants.FLASH_RED_EYE -> {
                requestBuilder!!.set(
                    CaptureRequest.CONTROL_AE_MODE,
                    CaptureRequest.CONTROL_AE_MODE_ON_AUTO_FLASH_REDEYE
                )
                requestBuilder.set(
                    CaptureRequest.FLASH_MODE,
                    CaptureRequest.FLASH_MODE_OFF
                )
            }
        }
    }

    /**
     * Updates the internal state of auto-focus to [.mAutoFocus].
     */
    internal fun updateAutoFocus() {
        if (autoFocus) {
            if (!isAutoFocusSupported) {
                mPreviewRequestBuilder!!.set(
                    CaptureRequest.CONTROL_AF_MODE,
                    CaptureRequest.CONTROL_AF_MODE_OFF
                )
            } else {
                if (isRecordingVideo) {
                    mPreviewRequestBuilder!!.set(
                        CaptureRequest.CONTROL_AF_MODE,
                        CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_VIDEO
                    )
                } else {
                    mPreviewRequestBuilder!!.set(
                        CaptureRequest.CONTROL_AF_MODE,
                        CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_PICTURE
                    )
                }
            }
        } else {
            mPreviewRequestBuilder!!.set(
                CaptureRequest.CONTROL_AF_MODE,
                CaptureRequest.CONTROL_AF_MODE_OFF
            )
        }
        mAFRegions = AutoFocusHelper.getZeroWeightRegion()
        mAERegions = AutoFocusHelper.getZeroWeightRegion()
        mPreviewRequestBuilder!!.set(CaptureRequest.CONTROL_AF_REGIONS, mAFRegions)
        mPreviewRequestBuilder!!.set(CaptureRequest.CONTROL_AE_REGIONS, mAERegions)
    }

    /**
     * Updates the internal state of manual focus.
     */
    internal fun updateManualFocus(x: Float, y: Float) {
        val sensorOrientation =
            mCameraCharacteristics!!.get(CameraCharacteristics.SENSOR_ORIENTATION)!!
        mAFRegions =
            AutoFocusHelper.afRegionsForNormalizedCoord(x, y, mCropRegion, sensorOrientation)
        mAERegions =
            AutoFocusHelper.aeRegionsForNormalizedCoord(x, y, mCropRegion, sensorOrientation)
        mPreviewRequestBuilder!!.set(CaptureRequest.CONTROL_AF_REGIONS, mAFRegions)
        mPreviewRequestBuilder!!.set(CaptureRequest.CONTROL_AE_REGIONS, mAERegions)
        mPreviewRequestBuilder!!.set(
            CaptureRequest.CONTROL_AF_MODE,
            CaptureRequest.CONTROL_AF_MODE_AUTO
        )
    }

    internal fun setManualFocusAt(x: Int, y: Int) {
        val mDisplayOrientation = activity!!.windowManager.defaultDisplay.rotation
        val points = FloatArray(2)
        points[0] = x.toFloat() / mBinding.texture!!.width
        points[1] = y.toFloat() / mBinding.texture!!.height
        val rotationMatrix = Matrix()
        rotationMatrix.setRotate(mDisplayOrientation.toFloat(), 0.5f, 0.5f)
        rotationMatrix.mapPoints(points)
        if (mPreviewRequestBuilder != null) {
            mIsManualFocusing = true
            updateManualFocus(points[0], points[1])
            if (mPreviewSession != null) {
                try {
                    mPreviewRequestBuilder!!.set(
                        CaptureRequest.CONTROL_AF_TRIGGER,
                        CaptureRequest.CONTROL_AF_TRIGGER_START
                    )
                    mPreviewSession!!.capture(
                        mPreviewRequestBuilder!!.build(),
                        null,
                        mBackgroundHandler
                    )
                    mPreviewRequestBuilder!!.set(
                        CaptureRequest.CONTROL_AF_TRIGGER,
                        CaptureRequest.CONTROL_AF_TRIGGER_IDLE
                    )
                    mPreviewSession!!.setRepeatingRequest(
                        mPreviewRequestBuilder!!.build(),
                        null,
                        mBackgroundHandler
                    )
                } catch (e: CameraAccessException) {
                    Log.e(TAG, "Failed to set manual focus.", e)
                } catch (e: IllegalStateException) {
                    Log.e(TAG, "Failed to set manual focus.", e)
                }

            }
            resumeAutoFocusAfterManualFocus()
        }
    }

    private fun resumeAutoFocusAfterManualFocus() {
        mBackgroundHandler!!.removeCallbacks(mAutoFocusRunnable)
        mBackgroundHandler!!.postDelayed(
            mAutoFocusRunnable,
            CameraConstants.FOCUS_HOLD_MILLIS.toLong()
        )
    }

    /**
     * Initiate a still image capture.
     */
    fun takePicture() {
        if (mPreviewSession == null)
            return
        mBinding.relCapture!!.isEnabled = false
        if (!mIsManualFocusing && autoFocus && isAutoFocusSupported) {
            Log.i(TAG, "takePicture lockFocus")
            capturePictureWhenFocusTimeout() //Sometimes, camera do not focus in some devices.
            lockFocus()
        } else {
            Log.i(TAG, "takePicture captureStill")
            captureStillPicture()
        }
        CameraUtil.shotAnimation(mBinding.rootLayout)
    }

    /**
     * Capture picture when auto focus timeout
     */
    private fun capturePictureWhenFocusTimeout() {
        if (mBackgroundHandler != null) {
            mBackgroundHandler!!.sendEmptyMessageDelayed(
                MSG_CAPTURE_PICTURE_WHEN_FOCUS_TIMEOUT,
                CameraConstants.AUTO_FOCUS_TIMEOUT_MS
            )
        }
    }

    /**
     * Remove capture message, because auto focus work correctly.
     */
    private fun removeCaptureMessage() {
        if (mBackgroundHandler != null) {
            mBackgroundHandler!!.removeMessages(MSG_CAPTURE_PICTURE_WHEN_FOCUS_TIMEOUT)
        }
    }

    /**
     * Lock the focus as the first step for a still image capture.
     */
    private fun lockFocus() {
        try {
            // This is how to tell the camera to lock focus.
            mPreviewRequestBuilder!!.set(
                CaptureRequest.CONTROL_AF_TRIGGER,
                CameraMetadata.CONTROL_AF_TRIGGER_START
            )
            // Tell #mCaptureCallback to wait for the lock.
            mState = STATE_WAITING_LOCK
            mPreviewSession!!.capture(
                mPreviewRequestBuilder!!.build(),
                mCaptureCallback,
                mBackgroundHandler
            )
        } catch (e: CameraAccessException) {
            e.printStackTrace()
        }

    }

    /**
     * Unlock the focus. This method should be called when still image capture sequence is
     * finished.
     */
    private fun unlockFocus() {
        try {
            // Reset the auto-focus trigger
            mPreviewRequestBuilder!!.set(
                CaptureRequest.CONTROL_AF_TRIGGER,
                CameraMetadata.CONTROL_AF_TRIGGER_CANCEL
            )
            mPreviewSession!!.capture(
                mPreviewRequestBuilder!!.build(), mCaptureCallback,
                mBackgroundHandler
            )

            updateAutoFocus()
            updateFlash(mPreviewRequestBuilder)
            // After this, the camera will go back to the normal state of preview.
            mState = STATE_PREVIEW
            mPreviewRequestBuilder!!.set(
                CaptureRequest.CONTROL_AF_TRIGGER,
                CaptureRequest.CONTROL_AF_TRIGGER_IDLE
            )

            if (mZoomRect != null)
                mPreviewRequestBuilder!!.set(CaptureRequest.SCALER_CROP_REGION, mZoomRect)

            mPreviewSession!!.setRepeatingRequest(
                mPreviewRequest!!, mCaptureCallback,
                mBackgroundHandler
            )
        } catch (e: CameraAccessException) {
            e.printStackTrace()
        }

    }

    /**
     * Run the precapture sequence for capturing a still image. This method should be called when
     * we get a response in [.mCaptureCallback] from [.lockFocus].
     */
    private fun runPrecaptureSequence() {
        try {
            // This is how to tell the camera to trigger.
            mPreviewRequestBuilder!!.set(
                CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER,
                CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER_START
            )
            // Tell #mCaptureCallback to wait for the precapture sequence to be set.
            mState = STATE_WAITING_PRECAPTURE
            mPreviewSession!!.capture(
                mPreviewRequestBuilder!!.build(),
                mCaptureCallback,
                mBackgroundHandler
            )
        } catch (e: CameraAccessException) {
            e.printStackTrace()
        }

    }

    /**
     * Capture a still picture. This method should be called when we get a response in
     * [.mCaptureCallback] from both [.lockFocus].
     */
    private fun captureStillPicture() {
        try {
            removeCaptureMessage()
            val activity = activity
            if (null == activity || null == mCameraDevice) {
                return
            }
            // This is the CaptureRequest.Builder that we use to take a picture.
            val captureBuilder =
                mCameraDevice!!.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE)
            captureBuilder.addTarget(mImageReader!!.surface)

            // Use the same AE and AF modes as the preview.
            //            captureBuilder.set(CaptureRequest.CONTROL_AF_MODE,
            //                CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_PICTURE);
            //            updateAutoFocus();
            updateFlash(captureBuilder)

            // Orientation
            val rotation = activity.windowManager.defaultDisplay.rotation
            captureBuilder.set(CaptureRequest.JPEG_ORIENTATION, getOrientation(rotation))

            if (mZoomRect != null) {
                captureBuilder.set(CaptureRequest.SCALER_CROP_REGION, mZoomRect)
            }

            val CaptureCallback = object : CameraCaptureSession.CaptureCallback() {

                override fun onCaptureCompleted(
                    session: CameraCaptureSession,
                    request: CaptureRequest,
                    result: TotalCaptureResult
                ) {
                    unlockFocus()
                }
            }

            mPreviewSession!!.stopRepeating()
            mPreviewSession!!.capture(captureBuilder.build(), CaptureCallback, mBackgroundHandler)
        } catch (e: CameraAccessException) {
            e.printStackTrace()
        }

    }

    /**
     * Retrieves the JPEG orientation from the specified screen rotation.
     *
     * @param rotation The screen rotation.
     * @return The JPEG orientation (one of 0, 90, 270, and 360)
     */
    private fun getOrientation(rotation: Int): Int {
        // Sensor orientation is 90 for most devices, or 270 for some devices (eg. Nexus 5X)
        // We have to take that into account and rotate JPEG properly.
        // For devices with orientation of 90, we simply return our mapping from DEFAULT_ORIENTATIONS.
        // For devices with orientation of 270, we need to rotate the JPEG 180 degrees.
        return (DEFAULT_ORIENTATIONS.get(rotation) + mSensorOrientation + 270) % 360
    }

    @Throws(IOException::class)
    private fun setupMediaRecorder() {
        val activity = activity ?: return
        mMediaRecorder!!.setAudioSource(MediaRecorder.AudioSource.MIC)
        mMediaRecorder!!.setVideoSource(MediaRecorder.VideoSource.SURFACE)
        mMediaRecorder!!.setOutputFormat(MediaRecorder.OutputFormat.MPEG_4)
        mNextVideoAbsolutePath = videoFilePath
        mMediaRecorder!!.setOutputFile(mNextVideoAbsolutePath)
        mMediaRecorder!!.setVideoEncodingBitRate(10000000)
        mMediaRecorder!!.setVideoFrameRate(30)
        mMediaRecorder!!.setVideoSize(mVideoSize!!.width, mVideoSize!!.height)
        mMediaRecorder!!.setVideoEncoder(MediaRecorder.VideoEncoder.H264)
        mMediaRecorder!!.setAudioEncoder(MediaRecorder.AudioEncoder.AAC)
        /*int rotation = activity.getWindowManager().getDefaultDisplay().getRotation();
        switch (mSensorOrientation) {
            case SENSOR_ORIENTATION_DEFAULT_DEGREES:
                mMediaRecorder.setOrientationHint(DEFAULT_ORIENTATIONS.get(rotation));
                break;
            case SENSOR_ORIENTATION_INVERSE_DEGREES:
                mMediaRecorder.setOrientationHint(INVERSE_ORIENTATIONS.get(rotation));
                break;
        }*/
        if (facing == CameraCharacteristics.LENS_FACING_BACK) {
            mMediaRecorder!!.setOrientationHint(mCamRotation)
        } else {
            if (mCamRotation == 90)
                mMediaRecorder!!.setOrientationHint(270)
            else if (mCamRotation == 180)
                mMediaRecorder!!.setOrientationHint(0)
            else if (mCamRotation == 0)
                mMediaRecorder!!.setOrientationHint(180)
            else
                mMediaRecorder!!.setOrientationHint(90)
        }
        mMediaRecorder!!.setMaxDuration(MAX_TIME_VIDEO)

        // Step 6: Prepare configured MediaRecorder

        mMediaRecorder!!.prepare()
    }


    /**
     * Start recording video
     */
    fun startRecordingVideo() {
        /**
         * if Builder media count -1 then not check condition
         * check selected media count is not more than {Builder media count}
         */
//        if (getBuilder().selectMediaCount != -1 && getBuilder().selectMediaCount == mAdapter.getSelectedMedia().size) {
//            Toast.makeText(context, getSelectCountExitsMessage(), Toast.LENGTH_SHORT).show()
//            return
//        }

        if (null == mCameraDevice || !mBinding.texture!!.isAvailable || null == mPreviewSize) {
            return
        }
        try {
            isRecordingVideo = true
            setupMediaRecorder()
            val texture = mBinding.texture!!.surfaceTexture!!
            texture.setDefaultBufferSize(mPreviewSize!!.width, mPreviewSize!!.height)
            mPreviewRequestBuilder =
                mCameraDevice!!.createCaptureRequest(CameraDevice.TEMPLATE_RECORD)
            val surfaces = ArrayList<Surface>()

            // Set up Surface for the camera preview
            val previewSurface = Surface(texture)
            surfaces.add(previewSurface)
            mPreviewRequestBuilder!!.addTarget(previewSurface)

            // Set up Surface for the MediaRecorder
            val recorderSurface = mMediaRecorder!!.surface
            surfaces.add(recorderSurface)
            mPreviewRequestBuilder!!.addTarget(recorderSurface)

            // Start a capture session
            // Once the session starts, we can update the UI and start recording
            mCameraDevice!!.createCaptureSession(
                surfaces,
                object : CameraCaptureSession.StateCallback() {

                    override fun onConfigured(cameraCaptureSession: CameraCaptureSession) {
                        mPreviewSession = cameraCaptureSession
                        try {
                            // Auto focus should be continuous for camera preview.
                            //                        mPreviewRequestBuilder.set(CaptureRequest.CONTROL_AF_MODE,
                            //                            CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_VIDEO);
                            updateAutoFocus()
                            // Flash is automatically enabled when necessary.
                            updateFlash(mPreviewRequestBuilder)

                            // For test
                            val stabilizationMode =
                                mPreviewRequestBuilder!!.get(CaptureRequest.CONTROL_VIDEO_STABILIZATION_MODE)
                            if (stabilizationMode != null && stabilizationMode == CaptureRequest.CONTROL_VIDEO_STABILIZATION_MODE_OFF) {
                                mPreviewRequestBuilder!!.set(
                                    CaptureRequest.CONTROL_VIDEO_STABILIZATION_MODE,
                                    CaptureRequest.CONTROL_VIDEO_STABILIZATION_MODE_ON
                                )
                            }

                            // Finally, we start displaying the camera preview.
                            mPreviewRequest = mPreviewRequestBuilder!!.build()
                            mPreviewSession!!.setRepeatingRequest(
                                mPreviewRequest!!,
                                null,
                                mBackgroundHandler
                            )
                            activity!!.runOnUiThread {
                                // Start recording
                                startRecordingTimer()
                                mMediaRecorder!!.start()
                            }
                        } catch (e: CameraAccessException) {
                            e.printStackTrace()
                        }

                    }

                    override fun onConfigureFailed(cameraCaptureSession: CameraCaptureSession) {
                        showToast("Start recording video configure failed")
                    }
                },
                mBackgroundHandler
            )
        } catch (e: CameraAccessException) {
            e.printStackTrace()
        } catch (e: IOException) {
            e.printStackTrace()
        }

    }

    private fun startRecordingTimer() {
        mBinding.linTimer!!.visibility = View.VISIBLE
        mBinding.imgCameraVideo.visibility = View.VISIBLE

         mCountDownTimer = object : CountDownTimer(MAX_TIME_VIDEO.toLong(), 100) {
            override fun onTick(millisUntilFinished: Long) {
                mBinding.progressBar!!.progress = (MAX_TIME_VIDEO - millisUntilFinished).toInt() / 3
                val formattedTime = String.format(
                    "%02d:%02d",
                    TimeUnit.MILLISECONDS.toMinutes(MAX_TIME_VIDEO - millisUntilFinished),
                    TimeUnit.MILLISECONDS.toSeconds(MAX_TIME_VIDEO - millisUntilFinished) - TimeUnit.MINUTES
                        .toSeconds(TimeUnit.MILLISECONDS.toHours(MAX_TIME_VIDEO - millisUntilFinished))
                )

                mBinding.txtTime.text = formattedTime
            }

            override fun onFinish() {
                stopRecordingVideo()
            }
        }.start()
    }

    /**
     * Stop recording video
     */
    fun stopRecordingVideo() {
        activity!!.runOnUiThread {
            val file = File(mNextVideoAbsolutePath)

            /**
             * if Builder media size -1 then not check condition
             * check selected media size is not more {Builder media size}
             */
            if (getBuilder().selectMediaMaxSize != -1L && getBuilder().selectMediaMaxSize < file.length()) {
                Toast.makeText(context, getMediaSizeExitsMessage(), Toast.LENGTH_SHORT)
                    .show()
                return@runOnUiThread
            }

            // UI
            isRecordingVideo = false

            //showToast("Video saved: " + mNextVideoAbsolutePath);
            Log.i(TAG, "Video saved: " + mNextVideoAbsolutePath)

            closeCamera()
            openCamera(mBinding.texture.width, mBinding.texture.height)

            /**
             * save capture image into gallery
             */

            /**
             * save capture image into gallery
             */
            val uri = Uri.fromFile(file)
            val video = Img(
                "",
                uri.toString(),
                uri.toString(),
                file.length(),
                true,
                "",
                Date()
            )

            addMediaToGallery(
                context,
                mNextVideoAbsolutePath ?: "",
                video.dateTaken.time,
                video.isVideo
            )


            //after recording video cropping

            val intent = Intent( activity!!, VideoTrimmerActivity::class.java )
            intent.putExtra(EXTRA_MEDIA, mNextVideoAbsolutePath)
            activity!!.startActivityForResult(intent,VIDEO_TRIMMER_REQUEST_CODE)


            //                getActivity().sendBroadcast(new Intent(Intent.ACTION_MEDIA_SCANNER_SCAN_FILE, Uri.fromFile(new File(mNextVideoAbsolutePath))));

            //                moveCropScreen(mNextVideoAbsolutePath, true, true);
        }
    }

    private fun getDisplayMediaType(): String {
        return when (getBuilder().mediaType) {
            MediaType.IMAGE -> context?.getString(R.string.image) ?: ""
            MediaType.VIDEO -> context?.getString(R.string.video) ?: ""
            MediaType.BOTH -> context?.getString(R.string.media) ?: ""
        }
    }

    private fun getMediaSizeExitsMessage(): String {
        val df = DecimalFormat("##.##")
        val size = df.format(getBuilder().selectMediaMaxSize / 1024.0)
        return "${context?.getString(R.string.you_cant_capture_more_than)} $size KB ${context?.getString(
            R.string.size_of
        )} ${getDisplayMediaType()}"
    }

    private fun getSelectCountExitsMessage(): String {
        return "${context?.getString(R.string.you_cant_capture_more_than)} ${getBuilder().selectMediaCount} ${getDisplayMediaType()}"
    }


    override fun onClick(v: View) {
        val i = v.id


        if (i == R.id.iv_gallery) {
            if (isMultiClick)
                return
            /**
             *Select Media
             */
            (activity as MediaPickerAct).openSelectMediaFrg()


        } else if (i == R.id.rel_capture) {
            if (isMultiClick)
                return

            /**
             * If media type "IMAGE" and "BOTH" then allow to capture image
             */
            if (getBuilder().mediaType == MediaType.VIDEO) {
                return
            }

            /**
             * if Builder media count -1 then not check condition
             * check selected media count is not more than {Builder media count}
             */
//            if (getBuilder().selectMediaCount != -1 && getBuilder().selectMediaCount == mAdapter.getSelectedMedia().size) {
//                Toast.makeText(context, getSelectCountExitsMessage(), Toast.LENGTH_SHORT).show()
//                return
//            }

            takePicture()

        } else if (i == R.id.img_cancel) {
            activity!!.onBackPressed()
        } else if (i == R.id.img_switch_camera) {
            if (isMultiClick)
                return


            facing = if (facing == CameraConstants.FACING_FRONT) {
                mBinding.isBackLens = true
                CameraConstants.FACING_BACK
            } else {
                mBinding.isBackLens = false
                CameraConstants.FACING_FRONT
            }

        } else if (i == R.id.img_preview) {
            if (isMultiClick)
                return

            /*if (isMediaTypeBoth)
                MediaPicker.start(Camera2Fragment.this, CameraUtil.REQ_MEDIA_PICK, SelectionCount, MediaPicker.MediaType.BOTH, isFromTimeline, isFromRight);
            else
                MediaPicker.start(Camera2Fragment.this, CameraUtil.REQ_MEDIA_PICK, SelectionCount, IMAGE, isFromTimeline, isFromRight);*/
        } else if (i == R.id.btn_send) {
           // openPreviewScreen(mAdapter.getSelectedMedia())
        }  else if(i==R.id.iv_flash){
            when (flash) {
                CameraConstants.FLASH_ON -> {
                    flash=CameraConstants.FLASH_OFF
                    mBinding.ivFlash.setImageResource(R.drawable.ic_flash_off_black_24dp)

                }
                CameraConstants.FLASH_OFF -> {
                    flash=CameraConstants.FLASH_AUTO
                    mBinding.ivFlash.setImageResource(R.drawable.ic_flash_auto_black_24dp)

                }
                CameraConstants.FLASH_AUTO -> {
                    flash=CameraConstants.FLASH_ON
                    mBinding.ivFlash.setImageResource(R.drawable.ic_flash_on_black_24dp)
                }
            }
        }
    }


    /**
     * Saves a JPEG [Image] into the specified [File].
     */
    private inner class ImageSaver internal constructor(
        /**
         * The JPEG image
         */
        private val mImage: Image,
        /**
         * The file we save the image into.
         */
        private val mFile: File, private var bitmap: Bitmap?
    ) : Runnable {

        override fun run() {
            if (facing == CameraCharacteristics.LENS_FACING_BACK) {
                bitmap = CameraUtil.rotate(bitmap, mCamRotation - 90)
            } else {
                if (mCamRotation == 90 || mCamRotation == 270)
                    bitmap = CameraUtil.rotate(bitmap, mCamRotation - 90)
                else
                    bitmap = CameraUtil.rotate(bitmap, mCamRotation + 90)
            }
            if (mNextPictureAbsolutePath == null) {
                return
            }
            try {
                val fos = FileOutputStream(File(mNextPictureAbsolutePath))
                bitmap!!.compress(Bitmap.CompressFormat.JPEG, 90, fos)
                //fos.write(data);
                fos.close()
            } catch (e: Exception) {
                Log.d(TAG, "Exception: " + e.message)
            }

            Log.e(TAG, "Save Image At " + mNextPictureAbsolutePath)
            mImage.close()

            activity!!.runOnUiThread {
                mBinding.relCapture.isEnabled = true

                val file = File(mNextPictureAbsolutePath)

                /**
                 * if Builder media size -1 then not check condition
                 * check selected media size is not more {Builder media size}
                 */
                if (getBuilder().selectMediaMaxSize != -1L && getBuilder().selectMediaMaxSize < file.length()) {
                    Toast.makeText(context, getMediaSizeExitsMessage(), Toast.LENGTH_SHORT)
                        .show()
                    return@runOnUiThread
                }

                /**
                 * save capture image into gallery
                 */
                val uri = Uri.fromFile(file)
                val image = Img(
                    "",
                    uri.toString(),
                    uri.toString(),
                    file.length(),
                    false,
                    "",
                    Date()
                )
              //  mAdapter.addMedia(image)
                addMediaToGallery(
                    context,
                    mNextPictureAbsolutePath ?: "",
                    image.dateTaken.time,
                    image.isVideo
                )
                //                    getActivity().sendBroadcast(new Intent(Intent.ACTION_MEDIA_SCANNER_SCAN_FILE, Uri.fromFile(new File(mNextPictureAbsolutePath))));
                setRecentImage()

                openPreviewScreen(image)
            }
        }

    }

    /**
     * Compares two `Size`s based on their areas.
     */
    private class CompareSizesByArea : Comparator<Size> {

        override fun compare(lhs: Size, rhs: Size): Int {
            // We cast here to ensure the multiplications won't overflow
            return java.lang.Long.signum(lhs.width.toLong() * lhs.height - rhs.width.toLong() * rhs.height)
        }
    }

    companion object {

        private val SENSOR_ORIENTATION_DEFAULT_DEGREES = 90
        private val SENSOR_ORIENTATION_INVERSE_DEGREES = 270

        private val DEFAULT_ORIENTATIONS = SparseIntArray()
        private val INVERSE_ORIENTATIONS = SparseIntArray()

        private val INTERNAL_FACINGS = SparseIntArray()

        init {
            INTERNAL_FACINGS.put(
                CameraConstants.FACING_BACK,
                CameraCharacteristics.LENS_FACING_BACK
            )
            INTERNAL_FACINGS.put(
                CameraConstants.FACING_FRONT,
                CameraCharacteristics.LENS_FACING_FRONT
            )
        }

        private val REQUEST_CAMERA_PERMISSION = 1

        private val FRAGMENT_DIALOG = "dialog"

        private val VIDEO_PERMISSIONS = arrayOf(
            Manifest.permission.CAMERA,
            Manifest.permission.RECORD_AUDIO,
            Manifest.permission.WRITE_EXTERNAL_STORAGE
        )

        init {
            DEFAULT_ORIENTATIONS.append(Surface.ROTATION_0, 90)
            DEFAULT_ORIENTATIONS.append(Surface.ROTATION_90, 0)
            DEFAULT_ORIENTATIONS.append(Surface.ROTATION_180, 270)
            DEFAULT_ORIENTATIONS.append(Surface.ROTATION_270, 180)
        }

        init {
            INVERSE_ORIENTATIONS.append(Surface.ROTATION_0, 270)
            INVERSE_ORIENTATIONS.append(Surface.ROTATION_90, 180)
            INVERSE_ORIENTATIONS.append(Surface.ROTATION_180, 90)
            INVERSE_ORIENTATIONS.append(Surface.ROTATION_270, 0)
        }

        /**
         * Tag for the [Log].
         */
        private val TAG = "Camera2Fragment"

        /**
         * Camera state: Showing camera preview.
         */
        private val STATE_PREVIEW = 0

        /**
         * Camera state: Waiting for the focus to be locked.
         */
        private val STATE_WAITING_LOCK = 1

        /**
         * Camera state: Waiting for the exposure to be precapture state.
         */
        private val STATE_WAITING_PRECAPTURE = 2

        /**
         * Camera state: Waiting for the exposure state to be something other than precapture.
         */
        private val STATE_WAITING_NON_PRECAPTURE = 3

        /**
         * Camera state: Picture was taken.
         */
        private val STATE_PICTURE_TAKEN = 4

        /**
         * Max preview width that is guaranteed by Camera2 API
         */
        private val MAX_PREVIEW_WIDTH = 1920

        /**
         * Max preview height that is guaranteed by Camera2 API
         */
        private val MAX_PREVIEW_HEIGHT = 1080


        private val MSG_CAPTURE_PICTURE_WHEN_FOCUS_TIMEOUT = 100

        /**
         * Max Time Video
         */
        private val MAX_TIME_VIDEO = 30000


        fun newInstance(): Camera2Fragment {
            val fragment = Camera2Fragment()
            return fragment
        }
    }
}
